{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8022663,"sourceType":"datasetVersion","datasetId":4727630}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.optim import AdamW","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport re\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nfrom transformers import RobertaTokenizerFast, RobertaForSequenceClassification, get_scheduler\nfrom torch.optim import Adam\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\ntrain_df = pd.read_csv(\"/kaggle/input/liar-dataset/train.tsv\", sep=\"\\t\", header=None)\nval_df   = pd.read_csv(\"/kaggle/input/liar-dataset/valid.tsv\", sep=\"\\t\", header=None)\ntest_df  = pd.read_csv(\"/kaggle/input/liar-dataset/test.tsv\", sep=\"\\t\", header=None)\n\ncols = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job_title\", \"state\", \"party\",\n        \"barely_true_ct\", \"false_ct\", \"half_true_ct\", \"mostly_true_ct\", \"pants_fire_ct\",\n        \"context\"]\ntrain_df.columns = cols\nval_df.columns = cols\ntest_df.columns = cols","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_map = {\n    \"pants-fire\": 0,\n    \"false\": 0,\n    \"barely-true\": 0,\n    \"half-true\": 0,\n    \"mostly-true\": 1,\n    \"true\": 1\n}\nfor df in [train_df, val_df, test_df]:\n    df[\"label\"] = df[\"label\"].map(label_map)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clean_text(text):\n    text = str(text).lower()\n    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", text)\n    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\nfor df in [train_df, val_df, test_df]:\n    df[\"statement\"] = df[\"statement\"].apply(clean_text)\n    df[\"context\"]   = df[\"context\"].fillna(\"\").apply(clean_text)\n    df[\"speaker\"]   = df[\"speaker\"].fillna(\"\").apply(clean_text)\n    df[\"party\"]     = df[\"party\"].fillna(\"\").apply(clean_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def combine_text(row):\n    return (\n        row[\"statement\"] + \" [SEP] speaker: \" + row[\"speaker\"] +\n        \" party: \" + row[\"party\"] + \" context: \" + row[\"context\"]\n    )\n\ntrain_texts = train_df.apply(combine_text, axis=1).tolist()\nval_texts   = val_df.apply(combine_text, axis=1).tolist()\ntest_texts  = test_df.apply(combine_text, axis=1).tolist()\n\ntrain_labels = train_df[\"label\"].tolist()\nval_labels   = val_df[\"label\"].tolist()\ntest_labels  = test_df[\"label\"].tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LIARDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = int(self.labels[idx])\n\n        encoding = self.tokenizer(\n            text,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n\n        return {\n            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n            \"labels\": torch.tensor(label, dtype=torch.long)\n        }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n\ntrain_dataset = LIARDataset(train_texts, train_labels, tokenizer)\nval_dataset   = LIARDataset(val_texts, val_labels, tokenizer)\ntest_dataset  = LIARDataset(test_texts, test_labels, tokenizer)\n\nclass_counts = train_df[\"label\"].value_counts().to_dict()\nclass_weights = [1.0 / class_counts[label] for label in train_df[\"label\"]]\nsampler = WeightedRandomSampler(class_weights, num_samples=len(class_weights), replacement=True)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler)\nval_loader   = DataLoader(val_dataset, batch_size=16)\ntest_loader  = DataLoader(test_dataset, batch_size=16)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\nmodel.to(device)\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=2e-5)\nnum_training_steps = len(train_loader) * 6  # 6 epochs\nlr_scheduler = get_scheduler(\"linear\", optimizer=optimizer,\n                             num_warmup_steps=0, num_training_steps=num_training_steps)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, optimizer, scheduler, loss_fn, epochs=6):\n    best_f1, patience, patience_counter = 0, 2, 0\n\n    for epoch in range(epochs):\n        model.train()\n        loop = tqdm(train_loader, leave=True)\n        total_loss, total_acc = 0, 0\n\n        for batch in loop:\n            optimizer.zero_grad()\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            logits = outputs.logits\n\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n\n            preds = torch.argmax(logits, dim=1)\n            acc = (preds == labels).cpu().numpy().mean()\n\n            total_loss += loss.item()\n            total_acc += acc\n\n            loop.set_description(f\"Epoch {epoch+1}\")\n            loop.set_postfix(loss=loss.item(), acc=acc)\n\n        avg_loss = total_loss / len(train_loader)\n        avg_acc = total_acc / len(train_loader)\n        print(f\"\\nEpoch {epoch+1} | Train Loss: {avg_loss:.4f} | Train Acc: {avg_acc:.4f}\")\n\n        val_acc, val_f1 = evaluate(model, val_loader, split=\"Validation\")\n\n        # Early stopping\n        if val_f1 > best_f1:\n            torch.save(model.state_dict(), \"best_roberta.pt\")\n            best_f1 = val_f1\n            patience_counter = 0\n            print(\" Saved new best model\")\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(\" Early stopping triggered\")\n                break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, loader, split=\"Test\"):\n    model.eval()\n    preds, labels = [], []\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            label = batch[\"labels\"].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            pred = torch.argmax(logits, dim=1)\n\n            preds.extend(pred.cpu().numpy())\n            labels.extend(label.cpu().numpy())\n\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average=\"weighted\")\n    print(f\"{split} Accuracy: {acc:.4f}, {split} F1: {f1:.4f}\")\n    if split != \"Validation\":\n        print(classification_report(labels, preds))\n        print(\"Confusion Matrix:\\n\", confusion_matrix(labels, preds))\n    return acc, f1\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(model, train_loader, val_loader, optimizer, lr_scheduler, loss_fn, epochs=6)\n\n\nmodel.load_state_dict(torch.load(\"best_roberta.pt\"))\nevaluate(model, test_loader, split=\"Final Test\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport shutil\n\n\nsave_dir = \"/kaggle/working/roberta_liar_model\"\nmodel.save_pretrained(save_dir)\ntokenizer.save_pretrained(save_dir)\n\nextra_info = {\n    \"task\": \"Fake News Detection - LIAR dataset (binary)\",\n    \"model\": \"roberta-base\",\n    \"final_test_accuracy\": float(test_acc),\n    \"final_test_f1\": float(test_f1)\n}\n\nimport json\nwith open(save_dir + \"/meta.json\", \"w\") as f:\n    json.dump(extra_info, f, indent=4)\n\n# 3. Zip the folder\nshutil.make_archive(\"/kaggle/working/roberta_liar_model\", 'zip', save_dir)\n\nprint(\"Model + tokenizer saved and zipped in /kaggle/working/\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}